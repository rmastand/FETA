{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd41c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from numba import cuda \n",
    "\n",
    "from helpers.composite_helpers import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebc06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_transform_for_scatter(idd, train_samp_1, train_samp_2, test_samp_1, test_samp_2, n_features, n_epochs, batch_size, lr, patience, device, update_epochs = 1, early_stop = True, visualize = True, seed = None):\n",
    "    \n",
    "    \n",
    "    # save the best model\n",
    "    val_loss_to_beat = 10000\n",
    "    best_epoch = -1\n",
    "    \n",
    "    \n",
    "    if seed is not None:\n",
    "        #print(f\"Using seed {seed}...\")\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "            \n",
    "    dense_net = NeuralNet(input_shape = n_features)\n",
    "    criterion = F.binary_cross_entropy #nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(dense_net.parameters(), lr=lr)\n",
    "\n",
    "    dense_net.to(device)\n",
    "    \n",
    "    if early_stop:\n",
    "        early_stopping = EarlyStopping(patience=patience)\n",
    "    \n",
    "    # transformed SIM has label 0, DAT has label 1\n",
    "    # make the input and output data\n",
    "    nn_train_data = np.concatenate((train_samp_1, train_samp_2))\n",
    "    nn_train_labs = np.concatenate((torch.zeros((train_samp_1.shape[0], 1)), torch.ones((train_samp_2.shape[0],1))))\n",
    "    \n",
    "\n",
    "\n",
    "    # get weights in case we're oversampling\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(nn_train_labs.reshape(-1)), nn_train_labs.reshape(-1))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    print(class_weights)\n",
    "        \n",
    "    \n",
    "    # train-test split\n",
    "    val_size = 0.2\n",
    "    \n",
    "    # train-val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(nn_train_data, nn_train_labs, test_size=val_size)\n",
    "    \n",
    "\n",
    "    X_test = np.concatenate((test_samp_1, test_samp_2))\n",
    "    y_test = np.concatenate((torch.zeros((test_samp_1.shape[0], 1)), torch.ones((test_samp_2.shape[0],1))))\n",
    "\n",
    "    \n",
    "    print(\"Train data, labels shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Val data, labels shape:\", X_val.shape, y_val.shape)\n",
    "    print(\"Test data, labels  shape:\", X_test.shape, y_test.shape)\n",
    "   \n",
    "\n",
    "    #for i in range(X_train.shape[1]):\n",
    "    #    print(f\"Feature {i} min, max for train: ({np.min(X_train[:,i])},{np.max(X_train[:,i])}), val: ({np.min(X_val[:,i])},{np.max(X_val[:,i])}), test: ({np.min(X_test[:,i])},{np.max(X_test[:,i])})\")  \n",
    "        \n",
    "\n",
    "\n",
    "    # send to device\n",
    "    X_train = np_to_torch(X_train, device)\n",
    "    X_val = np_to_torch(X_val, device)\n",
    "    X_test = np_to_torch(X_test, device)\n",
    "    y_train = np_to_torch(y_train, device)\n",
    "    y_val = np_to_torch(y_val, device)\n",
    "    \n",
    "\n",
    "    epochs, epochs_val = [], []\n",
    "    losses, losses_val = [], []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        # batching\n",
    "        indices_list = torch.split( torch.randperm( X_train.shape[0] ), batch_size )\n",
    "        # initialise lists to store batch stats\n",
    "        losses_batch_per_e = []\n",
    "        \n",
    "        for i, indices in enumerate( indices_list ): # going through the batches\n",
    "            # calculate the loss, backpropagate\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_data = X_train[indices]\n",
    "            batch_labels = y_train[indices]\n",
    "            \n",
    "            # get the weights\n",
    "            batch_weights = (torch.ones(batch_labels.shape, device=device)\n",
    "                        - batch_labels)*class_weights[0] \\\n",
    "                        + batch_labels*class_weights[1]\n",
    "\n",
    "            \n",
    "            loss = criterion(dense_net(batch_data), batch_labels, weight = batch_weights)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            losses_batch_per_e.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        epochs.append(epoch)\n",
    "        losses.append(np.mean(losses_batch_per_e))\n",
    "        \n",
    "        # validation\n",
    "        if epoch % update_epochs == 0:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # batching\n",
    "                val_indices_list = torch.split( torch.randperm( X_val.shape[0] ), batch_size )\n",
    "                # initialise lists to store batch stats\n",
    "                val_losses_batch_per_e = []\n",
    "\n",
    "                for i, indices in enumerate( val_indices_list ): # going through the batches\n",
    "                    # calculate the loss, backpropagate\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    batch_data = X_val[indices]\n",
    "                    batch_labels = y_val[indices]\n",
    "\n",
    "                    # get the weights\n",
    "                    batch_weights = (torch.ones(batch_labels.shape, device=device)\n",
    "                                - batch_labels)*class_weights[0] \\\n",
    "                                + batch_labels*class_weights[1]\n",
    "\n",
    "                    \n",
    "                    val_loss = criterion(dense_net(batch_data), batch_labels, weight = batch_weights) \n",
    "\n",
    "                    val_losses_batch_per_e.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "            epochs_val.append(epoch)\n",
    "            losses_val.append(np.mean(val_losses_batch_per_e))\n",
    "            \n",
    "            # see if the model has the best val loss\n",
    "            if np.mean(val_losses_batch_per_e) < val_loss_to_beat:\n",
    "                val_loss_to_beat = np.mean(val_losses_batch_per_e)\n",
    "                # save the model\n",
    "                model_path = \"garbage.pt\"\n",
    "                torch.save(dense_net, model_path)\n",
    "                best_epoch = epoch\n",
    "                \n",
    "            \n",
    "            if early_stop:\n",
    "                early_stopping(np.mean(val_losses_batch_per_e))\n",
    "                \n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "    print(\"Done training!\")\n",
    "    if visualize:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "        ax.plot(epochs, losses)\n",
    "        ax.plot(epochs_val, losses_val, label = \"val\")\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_title(idd)\n",
    "     \n",
    "        fig.show()\n",
    "\n",
    "    # evaluate\n",
    "               \n",
    "    \n",
    "    # load in the model with the best val loss\n",
    "    \n",
    "    print(f\"Loading in best model for {model_path}, val loss {val_loss_to_beat} from epoch {best_epoch}\")\n",
    "    dense_net_eval = torch.load(model_path)\n",
    "    dense_net_eval.eval()\n",
    "\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = dense_net_eval(X_test).detach().cpu().numpy()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e5a7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# load in the reverse rescales\n",
    "path_to_minmax = \"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/col_minmax.npy\"\n",
    "col_minmax = np.load(path_to_minmax)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "COMPUTING PARAMETERS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "# set the number of threads that pytorch will use\n",
    "torch.set_num_threads(2)\n",
    "\n",
    "# set gpu device\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print( \"Using device: \" + str( device ), flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dee274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "RUN PARAMETERS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "seed = 1\n",
    "n_features = 5\n",
    "num_signal_to_inject = 0\n",
    "oversampnum = 6\n",
    "\n",
    "\n",
    "epochs_NN =  100\n",
    "batch_size_NN = 128\n",
    "lr_NN = 0.001\n",
    "patience_NN = 10\n",
    "\n",
    "\n",
    "context_endpoints = (2500, 4500)\n",
    "\n",
    "\n",
    "bands_dict = {\"ob1\": [2500, 2900],\n",
    "              \"sb1\": [2900, 3300],\n",
    "              \"sr\" : [3300, 3700],\n",
    "              \"sb2\": [3700, 4100],\n",
    "              \"ob2\": [4100, 4500]}\n",
    "\n",
    "binning_scheme = np.linspace(-3.5, 3.5, 50)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "STS DATA\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "STS_dir = \"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/\"\n",
    "\n",
    "STS_bkg = ToyDataset(STS_dir, \"STS_bkg.npy\")\n",
    "STS_sig = ToyDataset(STS_dir, \"STS_sig.npy\")\n",
    "\n",
    "STS_bkg_dataset = STS_bkg.pull_from_mass_range([bands_dict[\"sr\"]])\n",
    "STS_sig_dataset = STS_sig.pull_from_mass_range([bands_dict[\"sr\"]])\n",
    "\n",
    "STS_bkg_dataset = minmaxscale(STS_bkg_dataset.data, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "STS_sig_dataset = minmaxscale(STS_sig_dataset.data, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd0db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "EVAL SIM2REAL\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# sim2real\n",
    "\n",
    "sim2real_exp_dir = f\"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_{num_signal_to_inject}sig_f/\"\n",
    "\n",
    "num_layers_BD_sim = 1\n",
    "num_hidden_features_BD_sim = 128\n",
    "num_blocks = 15\n",
    "\n",
    "num_layers_s2d = 2\n",
    "num_nodes_s2d = 16\n",
    "\n",
    "\n",
    "loc_id_BD_sim = f\"BD_sim_Masked_PRQ_AR_{num_layers_BD_sim}layers_{num_hidden_features_BD_sim}hidden_{num_blocks}blocks_{seed}seed\"\n",
    "loc_id_s2d = f\"PRQ_Coupling_{num_layers_s2d}layers_{num_nodes_s2d}nodes_{seed}seed\"\n",
    "BD_sim_training_dir = os.path.join(sim2real_exp_dir, f\"saved_models_{loc_id_BD_sim}/\")\n",
    "s2d_training_dir = os.path.join(BD_sim_training_dir, f\"saved_models_{loc_id_s2d}/\")\n",
    "s2d_samples_dir = os.path.join(s2d_training_dir, f\"npy_samples/\")\n",
    "\n",
    "oversamples_dir = os.path.join(s2d_training_dir, f\"oversampling_{oversampnum}/\")\n",
    "\n",
    "\n",
    "# load in the dat samples\n",
    "dat_samples_train = np.load(os.path.join(s2d_samples_dir, f\"sr_DAT.npy\")) \n",
    "dat_samples_train = minmaxscale(dat_samples_train, col_minmax, lower = -3, upper = 3, forward = False)\n",
    "dat_samples_train = minmaxscale(dat_samples_train, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "# cathode\n",
    "cathode_exp_dir = f\"/global/home/users/rrmastandrea/CATHODE/CATHODE_models/nsig_inj{num_signal_to_inject}/seed{seed}/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sim2real oversampled...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/rrmastandrea/computingML2/lib64/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0. 1.], y=[0. 0. 0. ... 1. 1. 1.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5828967792006209, 1: 3.515798712697484}\n",
      "Train data, labels shape: (682565, 5) (682565, 1)\n",
      "Val data, labels shape: (170642, 5) (170642, 1)\n",
      "Test data, labels  shape: (40000, 5) (40000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [05:38<20:01, 15.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training!\n",
      "Loading in best model for garbage.pt, val loss 0.6930084228515625 from epoch 12\n",
      "Evaluating cathode...\n",
      "{0: 0.65167375, 1: 2.148274668490757}\n",
      "Train data, labels shape: (417071, 5) (417071, 1)\n",
      "Val data, labels shape: (104268, 5) (104268, 1)\n",
      "Test data, labels  shape: (40000, 5) (40000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:58<13:18,  9.18s/it]"
     ]
    }
   ],
   "source": [
    "seed_NN = 4\n",
    "\n",
    "\n",
    "print(\"Evaluating sim2real oversampled...\")\n",
    "\n",
    "oversampled_sim_samples_train = np.load(os.path.join(oversamples_dir, f\"transBD.npy\"))\n",
    "oversampled_sim_samples_train = minmaxscale(oversampled_sim_samples_train, col_minmax, lower = -3, upper = 3, forward = False)\n",
    "oversampled_sim_samples_train = minmaxscale(oversampled_sim_samples_train, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "feta_results = analyze_transform_for_scatter(f\"sim2real_oversamp{oversampnum}_{seed_NN}\", oversampled_sim_samples_train[:,:-1], dat_samples_train[:,:-1], STS_bkg_dataset[:,:-1], STS_sig_dataset[:,:-1], n_features, epochs_NN, batch_size_NN, lr_NN, patience_NN, device, visualize = True, seed = seed_NN)\n",
    "np.save(\"feta_results\", feta_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Evaluating cathode...\")\n",
    "\n",
    "cathode_trans_samps = np.load(os.path.join(cathode_exp_dir, f\"SR_samples.npy\"))\n",
    "cathode_results = analyze_transform_for_scatter(f\"cathode_{seed_NN}\", cathode_trans_samps[:,:-1], dat_samples_train[:,:-1], STS_bkg_dataset[:,:-1], STS_sig_dataset[:,:-1], n_features, epochs_NN, batch_size_NN, lr_NN, patience_NN, device, visualize = True, seed = seed_NN)\n",
    "np.save(\"cathode_results\", cathode_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"\n",
    "\"\n",
    "SUPERVISED CLASSIFIER\n",
    "\"\n",
    "\"\"\"\n",
    "\n",
    "true_samples_dir = f\"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/\"\n",
    "\n",
    "\n",
    "print(\"Evaluating fully supervised case...\")\n",
    "\n",
    "true_samples_dir = f\"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/\"\n",
    "\n",
    "true_sup_bkg = np.load(os.path.join(true_samples_dir, f\"true_sup_bkg.npy\"))\n",
    "true_sup_sig = np.load(os.path.join(true_samples_dir, f\"true_sup_sig.npy\"))\n",
    "true_sup_bkg = minmaxscale(true_sup_bkg, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "true_sup_sig = minmaxscale(true_sup_sig, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "full_sup_results = analyze_transform_for_scatter(f\"full_sup_{seed_NN}\",true_sup_bkg[:,:-1], true_sup_sig[:,:-1], STS_bkg_dataset[:,:-1], STS_sig_dataset[:,:-1], n_features, epochs_NN, batch_size_NN, lr_NN, patience_NN, device, visualize = True, seed = seed_NN)\n",
    "np.save(\"full_sup_results\", full_sup_results)\n",
    "\n",
    "\n",
    "          \n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8649b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feta_results = np.load(\"feta_results.npy\")\n",
    "cathode_results = np.load(\"cathode_results.npy\")\n",
    "full_sup_results = np.load(\"full_sup_results.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122941d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.hist(full_sup_results[:20000], bins = 50, histtype = \"step\", label = \"Background\")\n",
    "plt.hist(full_sup_results[20000:], bins = 50, histtype = \"step\", label = \"Signal\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (18, 8))\n",
    "ax[0].scatter(feta_results[:20000], cathode_results[:20000], s = 1)\n",
    "ax[0].plot([0, 1], [0, 1], color = \"black\")\n",
    "ax[0].title.set_text(\"Background\")\n",
    "ax[0].set_xlabel(\"Feta\")\n",
    "ax[0].set_ylabel(\"Cathode\")\n",
    "\n",
    "ax[1].scatter(feta_results[20000:], cathode_results[20000:], s = 1)\n",
    "ax[1].plot([0, 1], [0, 1], color = \"black\")\n",
    "ax[1].title.set_text(\"Signal\")\n",
    "ax[1].set_xlabel(\"Feta\")\n",
    "ax[1].set_ylabel(\"Cathode\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (18, 8))\n",
    "ax[0].scatter(full_sup_results[:20000], cathode_results[:20000], s = 1)\n",
    "ax[0].title.set_text(\"Background\")\n",
    "ax[0].set_xlabel(\"FullSup\")\n",
    "ax[0].set_ylabel(\"Cathode\")\n",
    "\n",
    "ax[1].scatter(full_sup_results[20000:], cathode_results[20000:], s = 1)\n",
    "ax[1].title.set_text(\"Signal\")\n",
    "ax[1].set_xlabel(\"FullSup\")\n",
    "ax[1].set_ylabel(\"Cathode\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (18, 8))\n",
    "ax[0].scatter(full_sup_results[:20000], feta_results[:20000], s = 1)\n",
    "ax[0].title.set_text(\"Background\")\n",
    "ax[0].set_xlabel(\"FullSup\")\n",
    "ax[0].set_ylabel(\"Feta\")\n",
    "\n",
    "ax[1].scatter(full_sup_results[20000:], feta_results[20000:], s = 1)\n",
    "ax[1].title.set_text(\"Signal\")\n",
    "ax[1].set_xlabel(\"FullSup\")\n",
    "ax[1].set_ylabel(\"Feta\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a058eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac2299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9ea74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d029310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa6425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca2afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
