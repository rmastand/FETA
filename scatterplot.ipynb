{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd41c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from numba import cuda \n",
    "\n",
    "from helpers.composite_helpers import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc06c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c706d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def analyze_transform_for_scatter_kfold(idd, train_samp_1, train_samp_2, test_samp_1, test_samp_2, n_features, n_epochs, batch_size, lr, patience, device, early_stop = True, visualize = True, seed = None, k_folds = 5):\n",
    "    \n",
    "    if seed is not None:\n",
    "        #print(f\"Using seed {seed}...\")\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "    # transformed SIM has label 0, DAT has label 1\n",
    "    # make the input and output data\n",
    "    X_train = np.concatenate((train_samp_1, train_samp_2))\n",
    "    y_train = np.concatenate((torch.zeros((train_samp_1.shape[0], 1)), torch.ones((train_samp_2.shape[0],1))))    \n",
    "    \n",
    "    # get weights in case we're oversampling\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.reshape(-1)), y_train.reshape(-1))\n",
    "    class_weights = dict(enumerate(class_weights))   \n",
    "    \n",
    "    X_test = np.concatenate((test_samp_1, test_samp_2))\n",
    "    y_test = np.concatenate((torch.zeros((test_samp_1.shape[0], 1)), torch.ones((test_samp_2.shape[0],1))))\n",
    "    \n",
    "    print(\"Train data, labels shape:\", X_train.shape, y_train.shape)\n",
    "    print(\"Test data, labels  shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "    # send to device\n",
    "    X_train = np_to_torch(X_train, device)\n",
    "    X_test = np_to_torch(X_test, device)\n",
    "    y_train = np_to_torch(y_train, device)\n",
    "    \n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    fold_best_val_losses = []\n",
    "    \n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(X_train)):\n",
    "        \n",
    "    \n",
    "        # Print\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        X_train_fold = X_train[train_ids]\n",
    "        y_train_fold = y_train[train_ids]\n",
    "        \n",
    "        X_val_fold = X_train[val_ids]\n",
    "        y_val_fold = y_train[val_ids]\n",
    "        \n",
    "        train_set = torch.utils.data.TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_set = torch.utils.data.TensorDataset(X_val_fold, y_val_fold)\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = True)\n",
    "     \n",
    "        \n",
    "        # initialze the network\n",
    "        dense_net = NeuralNet(input_shape = n_features)\n",
    "        criterion = F.binary_cross_entropy \n",
    "        optimizer = torch.optim.Adam(dense_net.parameters(), lr=lr)\n",
    "        dense_net.to(device)\n",
    "        \n",
    "        if early_stop:\n",
    "            early_stopping = EarlyStopping(patience=patience)\n",
    "   \n",
    "        \n",
    "         # save the best model\n",
    "        val_loss_to_beat = 10000\n",
    "        best_epoch = -1\n",
    "\n",
    "        epochs, losses, losses_val = [], [], []\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            losses_batch_per_e = []\n",
    "            # batching    \n",
    "            for batch_index, (batch_data, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "                # calculate the loss, backpropagate\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # get the weights\n",
    "                batch_weights = (torch.ones(batch_labels.shape, device=device)\n",
    "                            - batch_labels)*class_weights[0] \\\n",
    "                            + batch_labels*class_weights[1]\n",
    "\n",
    "                loss = criterion(dense_net(batch_data), batch_labels, weight = batch_weights)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                losses_batch_per_e.append(loss.detach().cpu().numpy())\n",
    "\n",
    "            epochs.append(epoch)\n",
    "            losses.append(np.mean(losses_batch_per_e))\n",
    "\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                val_losses_batch_per_e = []\n",
    "                \n",
    "                for batch_index, (batch_data, batch_labels) in enumerate(val_loader):\n",
    "                    # calculate the loss, backpropagate\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # get the weights\n",
    "                    batch_weights = (torch.ones(batch_labels.shape, device=device)\n",
    "                                - batch_labels)*class_weights[0] \\\n",
    "                                + batch_labels*class_weights[1]\n",
    "\n",
    "                    val_loss = criterion(dense_net(batch_data), batch_labels, weight = batch_weights) \n",
    "                    val_losses_batch_per_e.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "                losses_val.append(np.mean(val_losses_batch_per_e))\n",
    "\n",
    "                # see if the model has the best val loss\n",
    "                if np.mean(val_losses_batch_per_e) < val_loss_to_beat:\n",
    "                    val_loss_to_beat = np.mean(val_losses_batch_per_e)\n",
    "                    # save the model\n",
    "                    model_path = f\".{idd}_fold{fold}.pt\"\n",
    "                    torch.save(dense_net, model_path)\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                if early_stop:\n",
    "                    early_stopping(np.mean(val_losses_batch_per_e))\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "\n",
    "        print(f\"Done training fold {fold}. Best val loss {val_loss_to_beat} at epoch {best_epoch}\")\n",
    "        if visualize:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "            ax.plot(epochs, losses)\n",
    "            ax.plot(epochs, losses_val, label = \"val\")\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(\"Epoch\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "            ax.set_title(f\"{idd}_fold{fold}\")\n",
    "            fig.show()\n",
    "\n",
    "        # evaluate\n",
    "        fold_best_val_losses.append(val_loss_to_beat)\n",
    "            \n",
    "    \n",
    "    # load in the model / fold with the best val loss \n",
    "    best_model_index = np.argmin(fold_best_val_losses)\n",
    "    best_model_path = f\".{idd}_fold{best_model_index}.pt\"\n",
    "    print(f\"Loading in best model for {best_model_path}, val loss {np.min(fold_best_val_losses)} from fold {best_model_index}\")\n",
    "    \n",
    "    dense_net_eval = torch.load(best_model_path)\n",
    "    # save the best model\n",
    "    later_model_path = f\".{idd}_fold{fold}_best_model.pt\"\n",
    "    print(f\"saving best model as {later_model_path}\")\n",
    "    torch.save(dense_net_eval, later_model_path)\n",
    "    \n",
    "    dense_net_eval.eval()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = dense_net_eval(X_test).detach().cpu().numpy()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e5a7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# load in the reverse rescales\n",
    "path_to_minmax = \"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/col_minmax.npy\"\n",
    "col_minmax = np.load(path_to_minmax)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "COMPUTING PARAMETERS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "# set the number of threads that pytorch will use\n",
    "torch.set_num_threads(2)\n",
    "\n",
    "# set gpu device\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print( \"Using device: \" + str( device ), flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dee274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "RUN PARAMETERS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "seed = 1\n",
    "n_features = 5\n",
    "num_signal_to_inject = 2500\n",
    "oversampnum = 6\n",
    "\n",
    "\n",
    "epochs_NN =  100\n",
    "batch_size_NN = 256\n",
    "lr_NN = 0.001\n",
    "patience_NN = 5\n",
    "\n",
    "\n",
    "context_endpoints = (2500, 4500)\n",
    "\n",
    "\n",
    "bands_dict = {\"ob1\": [2500, 2900],\n",
    "              \"sb1\": [2900, 3300],\n",
    "              \"sr\" : [3300, 3700],\n",
    "              \"sb2\": [3700, 4100],\n",
    "              \"ob2\": [4100, 4500]}\n",
    "\n",
    "binning_scheme = np.linspace(-3.5, 3.5, 50)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "STS DATA\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "STS_dir = \"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/\"\n",
    "\n",
    "STS_bkg = ToyDataset(STS_dir, \"STS_bkg.npy\")\n",
    "STS_sig = ToyDataset(STS_dir, \"STS_sig.npy\")\n",
    "\n",
    "STS_bkg_dataset = STS_bkg.pull_from_mass_range([bands_dict[\"sr\"]])\n",
    "STS_sig_dataset = STS_sig.pull_from_mass_range([bands_dict[\"sr\"]])\n",
    "\n",
    "STS_bkg_dataset = minmaxscale(STS_bkg_dataset.data, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "STS_sig_dataset = minmaxscale(STS_sig_dataset.data, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd0db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "EVAL SIM2REAL\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# sim2real\n",
    "\n",
    "sim2real_exp_dir = f\"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_{num_signal_to_inject}sig_f/\"\n",
    "\n",
    "num_layers_BD_sim = 1\n",
    "num_hidden_features_BD_sim = 128\n",
    "num_blocks = 15\n",
    "\n",
    "num_layers_s2d = 2\n",
    "num_nodes_s2d = 16\n",
    "\n",
    "\n",
    "loc_id_BD_sim = f\"BD_sim_Masked_PRQ_AR_{num_layers_BD_sim}layers_{num_hidden_features_BD_sim}hidden_{num_blocks}blocks_{seed}seed\"\n",
    "loc_id_s2d = f\"PRQ_Coupling_{num_layers_s2d}layers_{num_nodes_s2d}nodes_{seed}seed\"\n",
    "BD_sim_training_dir = os.path.join(sim2real_exp_dir, f\"saved_models_{loc_id_BD_sim}/\")\n",
    "s2d_training_dir = os.path.join(BD_sim_training_dir, f\"saved_models_{loc_id_s2d}/\")\n",
    "s2d_samples_dir = os.path.join(s2d_training_dir, f\"npy_samples/\")\n",
    "\n",
    "oversamples_dir = os.path.join(s2d_training_dir, f\"oversampling_{oversampnum}/\")\n",
    "\n",
    "\n",
    "# load in the dat samples\n",
    "dat_samples_train = np.load(os.path.join(s2d_samples_dir, f\"sr_DAT.npy\")) \n",
    "dat_samples_train = minmaxscale(dat_samples_train, col_minmax, lower = -3, upper = 3, forward = False)\n",
    "dat_samples_train = minmaxscale(dat_samples_train, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "# cathode\n",
    "cathode_exp_dir = f\"/global/home/users/rrmastandrea/CATHODE/CATHODE_models/nsig_inj{num_signal_to_inject}/seed{seed}/\"\n",
    "\n",
    "# curtains\n",
    "curtains_exp_dir = f\"/global/home/users/rrmastandrea/curtains/images/NSF_CURT_{num_signal_to_inject}sig_seed{seed}/Transformer/evaluation/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403b4a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sim2real oversampled...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/rrmastandrea/computingML2/lib64/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0. 1.], y=[0. 0. 0. ... 1. 1. 1.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data, labels shape: (855173, 5) (855173, 1)\n",
      "Test data, labels  shape: (40000, 5) (40000, 1)\n",
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:31<15:25, 10.17s/it]"
     ]
    }
   ],
   "source": [
    "seed_NN = 4\n",
    "\n",
    "\n",
    "print(\"Evaluating sim2real oversampled...\")\n",
    "\n",
    "oversampled_sim_samples_train = np.load(os.path.join(oversamples_dir, f\"transBD.npy\"))\n",
    "oversampled_sim_samples_train = minmaxscale(oversampled_sim_samples_train, col_minmax, lower = -3, upper = 3, forward = False)\n",
    "oversampled_sim_samples_train = minmaxscale(oversampled_sim_samples_train, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "feta_results = analyze_transform_for_scatter_kfold(f\"sim2real_oversamp{oversampnum}_{seed_NN}_{num_signal_to_inject}\", oversampled_sim_samples_train[:,:-1], dat_samples_train[:,:-1], STS_bkg_dataset[:,:-1], STS_sig_dataset[:,:-1], n_features, epochs_NN, batch_size_NN, lr_NN, patience_NN, device, visualize = True, seed = seed_NN, early_stop = True)\n",
    "np.save(f\"feta_results_{num_signal_to_inject}\", feta_results)\n",
    "\n",
    "print(3*\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Evaluating cathode...\")\n",
    "\n",
    "cathode_trans_samps = np.load(os.path.join(cathode_exp_dir, f\"SR_samples.npy\"))\n",
    "cathode_results = analyze_transform_for_scatter_kfold(f\"cathode_{seed_NN}_{num_signal_to_inject}\", cathode_trans_samps[:,:-1], dat_samples_train[:,:-1], STS_bkg_dataset[:,:-1], STS_sig_dataset[:,:-1], n_features, epochs_NN, batch_size_NN, lr_NN, patience_NN, device, visualize = True, seed = seed_NN, early_stop = True)\n",
    "np.save(f\"cathode_results_{num_signal_to_inject}\", cathode_results)\n",
    "print(3*\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Evaluating curtains...\")\n",
    "curtains_trans_samps = np.load(os.path.join(curtains_exp_dir, f\"samples_sb1_2_to_sr.npy\"))\n",
    "curtains_trans_samps = minmaxscale(curtains_trans_samps, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "curtains_results = analyze_transform_for_scatter_kfold(f\"curtains_{seed_NN}_{num_signal_to_inject}\", curtains_trans_samps[:,:-1], dat_samples_train[:,:-1], STS_bkg_dataset[:,:-1], STS_sig_dataset[:,:-1], n_features, epochs_NN, batch_size_NN, lr_NN, patience_NN, device, visualize = True, seed = seed_NN, early_stop = True)\n",
    "np.save(f\"curtains_results_{num_signal_to_inject}\", curtains_results)    \n",
    "print(3*\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"\n",
    "\"\n",
    "SUPERVISED CLASSIFIER\n",
    "\"\n",
    "\"\"\"\n",
    "\n",
    "true_samples_dir = f\"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/\"\n",
    "\n",
    "\n",
    "print(\"Evaluating fully supervised case...\")\n",
    "\n",
    "true_samples_dir = f\"/global/home/users/rrmastandrea/CURTAINS_SALAD/LHCO_STS/data/\"\n",
    "\n",
    "true_sup_bkg = np.load(os.path.join(true_samples_dir, f\"true_sup_bkg.npy\"))\n",
    "true_sup_sig = np.load(os.path.join(true_samples_dir, f\"true_sup_sig.npy\"))\n",
    "true_sup_bkg = minmaxscale(true_sup_bkg, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "true_sup_sig = minmaxscale(true_sup_sig, col_minmax, lower = 0, upper = 1, forward = True)\n",
    "\n",
    "full_sup_results = analyze_transform_for_scatter_kfold(f\"full_sup_{seed_NN}_{num_signal_to_inject}\",true_sup_bkg[:,:-1], true_sup_sig[:,:-1], STS_bkg_dataset[:,:-1], STS_sig_dataset[:,:-1], n_features, epochs_NN, batch_size_NN, lr_NN, patience_NN, device, visualize = True, seed = seed_NN, early_stop = True)\n",
    "np.save(f\"full_sup_results_{num_signal_to_inject}\", full_sup_results)\n",
    "print(3*\"\\n\")\n",
    "\n",
    "          \n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8649b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_signal_to_inject = 0\n",
    "\n",
    "\n",
    "feta_results = np.load(f\"feta_results_{num_signal_to_inject}.npy\")\n",
    "cathode_results = np.load(f\"cathode_results_{num_signal_to_inject}.npy\")\n",
    "curtains_results = np.load(f\"curtains_results_{num_signal_to_inject}.npy\")\n",
    "\n",
    "full_sup_results = np.load(f\"full_sup_results_{num_signal_to_inject}.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "\n",
    "def standardize(x):\n",
    "    return (x - np.mean(x))/np.std(x)\n",
    "\n",
    "stand_feta = standardize(feta_results)\n",
    "stand_cathode = standardize(cathode_results)\n",
    "stand_curtains = standardize(curtains_results)\n",
    "stand_full_sup = standardize(full_sup_results)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122941d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.hist(full_sup_results[:20000], bins = 50, histtype = \"step\", label = \"Background\")\n",
    "plt.hist(full_sup_results[20000:], bins = 50, histtype = \"step\", label = \"Signal\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"science.mplstyle\")\n",
    "dpi = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a058eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nn = 2000\n",
    "ll = 5\n",
    "\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "\n",
    "plt.scatter(stand_feta[:nn], stand_cathode[:nn], s = 1, label = \"Background\", color = \"pink\")\n",
    "plt.scatter(stand_feta[20000:20000+nn], stand_cathode[20000:20000+nn], s = 1, label = \"Signal\", color = \"purple\")\n",
    "plt.plot([-ll, ll], [-ll, ll], color = \"black\")\n",
    "plt.xlim(-ll, ll)\n",
    "plt.ylim(-ll, ll)\n",
    "plt.legend(markerscale=6)\n",
    "plt.xlabel(\"Feta (standardized)\")\n",
    "plt.ylabel(\"Cathode (standardized)\")\n",
    "fig.savefig(\"paper_plots/feta_v_cathode.pdf\", dpi = dpi)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "\n",
    "plt.scatter(stand_feta[:nn], stand_curtains[:nn], s = 1, label = \"Background\", color = \"pink\")\n",
    "plt.scatter(stand_feta[20000:20000+nn], stand_curtains[20000:20000+nn], s = 1, label = \"Signal\", color = \"purple\")\n",
    "plt.plot([-ll, ll], [-ll, ll], color = \"black\")\n",
    "plt.xlim(-ll, ll)\n",
    "plt.ylim(-ll, ll)\n",
    "plt.legend(markerscale=6)\n",
    "plt.xlabel(\"Feta (standardized)\")\n",
    "plt.ylabel(\"Curtains (standardized)\")\n",
    "fig.savefig(\"paper_plots/feta_v_curtains.pdf\", dpi = dpi)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac2299",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nn = 10000\n",
    "f = 20\n",
    "ll = 4\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (17, 7))\n",
    "\n",
    "ax[0].scatter(stand_feta[:nn], stand_cathode[:nn], s = 1, label = \"Background\", color = \"pink\")\n",
    "ax[0].plot([-ll, ll], [-ll, ll], color = \"black\")\n",
    "#ax[0].text(-3, 2, f\"$n_s = {num_signal_to_inject}$\", fontsize = f+2)\n",
    "ax[0].set_xlim(-ll, ll)\n",
    "ax[0].set_ylim(-ll, ll)\n",
    "ax[0].legend(markerscale=10, fontsize = f, loc = \"upper left\")\n",
    "ax[0].set_xlabel(\"FETA\")\n",
    "ax[0].set_ylabel(\"CATHODE\")\n",
    "\n",
    "ax[1].scatter(stand_feta[20000:20000+nn], stand_cathode[20000:20000+nn], s = 1, label = \"Signal\", color = \"purple\")\n",
    "ax[1].plot([-ll, ll], [-ll, ll], color = \"black\")\n",
    "#ax[0].text(-3, 2, f\"$n_s = {num_signal_to_inject}$\", fontsize = f+2)\n",
    "ax[1].set_xlim(-ll, ll)\n",
    "ax[1].set_ylim(-ll, ll)\n",
    "ax[1].legend(markerscale=10, loc = \"upper left\", fontsize = f)\n",
    "ax[1].set_xlabel(\"FETA\")\n",
    "ax[1].set_ylabel(\"CATHODE\")\n",
    "\n",
    "fig.savefig(f\"paper_plots/feta_v_cathode_{num_signal_to_inject}.pdf\", dpi = dpi)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (17, 7))\n",
    "\n",
    "ax[0].scatter(stand_feta[:nn], stand_curtains[:nn], s = 1, label = \"Background\", color = \"pink\")\n",
    "ax[0].plot([-ll, ll], [-ll, ll], color = \"black\")\n",
    "ax[0].set_xlim(-ll, ll)\n",
    "ax[0].set_ylim(-ll, ll)\n",
    "ax[0].legend(markerscale=10, loc = \"upper left\", fontsize = f)\n",
    "ax[0].set_xlabel(\"FETA\")\n",
    "ax[0].set_ylabel(\"CURTAINS\")\n",
    "\n",
    "ax[1].scatter(stand_feta[20000:20000+nn], stand_curtains[20000:20000+nn], s = 1, label = \"Signal\", color = \"purple\")\n",
    "ax[1].plot([-ll, ll], [-ll, ll], color = \"black\")\n",
    "\n",
    "ax[1].set_xlim(-ll, ll)\n",
    "ax[1].set_ylim(-ll, ll)\n",
    "ax[1].legend(markerscale=10, loc = \"upper left\", fontsize = f)\n",
    "ax[1].set_xlabel(\"FETA\")\n",
    "ax[1].set_ylabel(\"CURTAINS\")\n",
    "\n",
    "fig.savefig(f\"paper_plots/feta_v_curtains_{num_signal_to_inject}.pdf\", dpi = dpi)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9ea74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d029310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa6425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca2afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43b334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b445d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
