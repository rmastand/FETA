{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52780f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyyaml in /global/home/users/rrmastandrea/.local/lib/python3.8/site-packages (6.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "from helpers.datasets import *\n",
    "from helpers.plotting import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "plt.style.use(\"science.mplstyle\")\n",
    "cm = matplotlib.cm.get_cmap('Greens')\n",
    "from matplotlib.backends.backend_pdf import PdfPages as pp\n",
    "\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916c000f-a946-447d-991f-c31c8d4146e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"workflow.yaml\", \"r\") as file:\n",
    "    workflow = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09d0c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/home/users/rrmastandrea/FETA/LHCO_STS_3prong/data/\n"
     ]
    }
   ],
   "source": [
    "# directories\n",
    "feta_dir = \"/global/home/users/rrmastandrea/FETA/\"\n",
    "STS_dir = \"/global/home/users/rrmastandrea/FETA/LHCO_STS_{project_id}/data/\".format(project_id = workflow[\"project_id\"])\n",
    "print(STS_dir)\n",
    "col_minmax = np.load(os.path.join(STS_dir, \"col_minmax.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71038a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset generation parameters\n",
    "\n",
    "n_features = 6\n",
    "\n",
    "bands_dict = workflow[\"bands_dict\"]\n",
    "\n",
    "bands_to_analyze = [\"sb1\", \"sr\", \"sb2\"]\n",
    "feature_labels = [r\"$f_0$\", r\"$f_1$\", r\"$f_2$\", r\"$f_3$\", r\"$f_4$\", r\"$f_5$\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ad115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_from_mass_range(dataset, mass_ranges):\n",
    "\n",
    "        \"\"\"\n",
    "        mass_ranges is a list of lists [low_bound, high_bound]\n",
    "        \"\"\"\n",
    "\n",
    "        selected_data = []\n",
    "\n",
    "        for mass_range in mass_ranges:\n",
    "            loc = np.where((dataset[:, 5] >= mass_range[0]) & (dataset[:, 5] < mass_range[1]))[0]\n",
    "            selected_data.append( dataset[loc, :] )\n",
    "        selected_data = np.concatenate(selected_data)\n",
    "        np.random.shuffle(selected_data)\n",
    "\n",
    "        return selected_data\n",
    "\n",
    "def pull_n_signal_events(n, sig_dataset):\n",
    "    \n",
    "    selected_sig_indices = np.random.choice(sig_dataset.shape[0], size=n, replace=False)\n",
    "    selected_sig_events = sig_dataset[selected_sig_indices]\n",
    "    \n",
    "    return(selected_sig_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44563eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "herwig_bkg_dict = pickle.load( open( f\"post_STS_wide_{project_id}/herwig_bkg_dict.p\", \"rb\" ) )\n",
    "pythia_bkg_dict = pickle.load( open( f\"post_STS_wide_{project_id}/pythia_bkg.p\", \"rb\" ) )\n",
    "pythia_sig_dict = pickle.load( open( f\"post_STS_wide_{project_id}/pythia_sig_nonSTS.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "num_sig_events = {}\n",
    "\n",
    "for b in bands_to_analyze:\n",
    "    print(f\"Number of events in band {b}:\")\n",
    "    \n",
    "    ll = len(herwig_bkg_dict[b])\n",
    "    print(f\"Herwig bkg: {ll}\")\n",
    "    \n",
    "    ll = len(pythia_bkg_dict[b])\n",
    "    print(f\"Pythia bkg: {ll}\")\n",
    "    \n",
    "    ll = len(pythia_sig_dict[b])\n",
    "    num_sig_events[b] = ll\n",
    "    print(f\"Pythia sig: {ll}\")\n",
    "          \n",
    "    print()\n",
    "    \n",
    "    \n",
    "num_total_sig_events = sum(list(num_sig_events.values()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6edffe1",
   "metadata": {},
   "source": [
    "### Pull n signal events from the range (sb1 -> sb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f39911",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_signal_to_inject = 1500\n",
    "\n",
    "# initialize the \"data\"\n",
    "pythia_bkg_w_inj = []\n",
    "herwig_bkg = []\n",
    "\n",
    "# to get the ratios right: to inject nnum_signal_to_inject events:\n",
    "    #for each band, inject num_signal_to_inject*num_sig_events[band]/num_total_sig_events\n",
    "    \n",
    "for b in bands_to_analyze:\n",
    "    n_sig_band = int(num_signal_to_inject*num_sig_events[b]/num_total_sig_events)\n",
    "    selected_signal_band = pull_n_signal_events(n_sig_band, pythia_sig_dict[b])\n",
    "    \n",
    "    pythia_bkg_w_inj.append(pythia_bkg_dict[b])\n",
    "    herwig_bkg.append(herwig_bkg_dict[b])\n",
    "    pythia_bkg_w_inj.append(selected_signal_band)\n",
    "\n",
    "    print(f\"Num bkg events in band {b}: {pythia_bkg_dict[b].shape}\")\n",
    "    print(f\"Num signal events injected in band {b}: {selected_signal_band.shape}\")\n",
    "    print()\n",
    "\n",
    "pythia_bkg_w_inj = np.vstack(pythia_bkg_w_inj) \n",
    "herwig_bkg = np.vstack(herwig_bkg) \n",
    "\n",
    "    \n",
    "\n",
    "np.random.shuffle(pythia_bkg_w_inj)\n",
    "\n",
    "print(f\"Pythia background w/ injection, SB1 to SB2: {pythia_bkg_w_inj.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a956e29",
   "metadata": {},
   "source": [
    "## Nice plots of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf54803",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 10000\n",
    "bins = 50\n",
    "dpi = 800\n",
    "\n",
    "# Scatterplot the features\n",
    "#fig = scatterplot_features(herwig_bkg, pythia_bkg_w_inj, bins, n_features, feature_labels, n_plot = n_plot)\n",
    "#fig.show()\n",
    "\n",
    "\n",
    "# 1D histograms\n",
    "labels = [\"$m_{J_1}$\", \"$\\Delta m_{JJ}$\", \"$\\\\tau^{21}_{J_1}$\", \"$\\\\tau^{21}_{J_2}$\", \"$\\Delta R_{JJ}$\", \"$m_{JJ}$\"]\n",
    "\n",
    "\n",
    "fig = plot_feature_histograms(herwig_bkg, pythia_bkg_w_inj, bins, n_features, labels)\n",
    "#fig.savefig(f\"paper_plots/LHC_datasets.pdf\", dpi = dpi)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce1774",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5baf572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save everything out\n",
    "\n",
    "dataset_config_string = f\"LHCO_{num_signal_to_inject}sig_{project_id}/\"\n",
    "data_dir = os.path.join(feta_dir, dataset_config_string, \"data\")\n",
    "\n",
    "print(\"Making dataset directory at\", data_dir, \"...\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# prepare the density estimation datasets\n",
    "train_herwig = pull_from_mass_range(herwig_bkg, [bands_dict[\"sb1\"], bands_dict[\"sr\"], bands_dict[\"sb2\"]])\n",
    "sb1_sb2_pythia = pull_from_mass_range(pythia_bkg_w_inj, [bands_dict[\"sb1\"], bands_dict[\"sb2\"]])\n",
    "\n",
    "print(\"SB training set:\")\n",
    "print(train_herwig.shape,sb1_sb2_pythia.shape )\n",
    "# split the data into train-val\n",
    "sim_train, sim_val = train_test_split(train_herwig, test_size=0.2, random_state=8)\n",
    "dat_train, dat_val = train_test_split(sb1_sb2_pythia, test_size=0.2, random_state=8)\n",
    "\n",
    "np.save(os.path.join(data_dir, \"train_sim.npy\"), sim_train[:, :-1])\n",
    "np.save(os.path.join(data_dir, \"val_sim.npy\"), sim_val[:, :-1])\n",
    "np.save(os.path.join(data_dir, \"train_dat.npy\"), dat_train[:, :-1])\n",
    "np.save(os.path.join(data_dir, \"val_dat.npy\"), dat_val[:, :-1])\n",
    "\n",
    "# prepare the classifier training\n",
    "sr_herwig = pull_from_mass_range(herwig_bkg, [bands_dict[\"sr\"]])\n",
    "sr_pythia = pull_from_mass_range(pythia_bkg_w_inj, [bands_dict[\"sr\"]])\n",
    "\n",
    "print(\"SR training set:\")\n",
    "print(sr_herwig.shape,sr_pythia.shape )\n",
    "\n",
    "np.save(os.path.join(data_dir, \"classif_train_sim.npy\"), sr_herwig[:, :-1])\n",
    "np.save(os.path.join(data_dir, \"classif_train_dat.npy\"), sr_pythia[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59678c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021095f4",
   "metadata": {},
   "source": [
    "## Save out a training dataset for CATHODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_set_for_cathode(dset):\n",
    "    \n",
    "    # rescale the non-mass features\n",
    "    \n",
    "    dset[:,:-2] = minmaxscale(dset[:,:-2], col_minmax[:-1], lower = 0, upper  = 1.0)\n",
    "    \n",
    "    cathode_dset = np.zeros(dset.shape)\n",
    "    \n",
    "    cathode_dset[:,0] = dset[:,5] / 1000. # divide mass by 1000\n",
    "    cathode_dset[:,1] = dset[:,0]\n",
    "    cathode_dset[:,2] = dset[:,1]\n",
    "    cathode_dset[:,3] = dset[:,2]\n",
    "    cathode_dset[:,4] = dset[:,3]\n",
    "    cathode_dset[:,5] = dset[:,4]\n",
    "    cathode_dset[:,6] = dset[:,6]\n",
    "\n",
    "    \n",
    "    return cathode_dset\n",
    "\n",
    "\n",
    "cathode_SB_data_train = prep_set_for_cathode(dat_train)\n",
    "cathode_SB_data_val = prep_set_for_cathode(dat_val)\n",
    "cathode_SR_data = prep_set_for_cathode(sr_pythia)\n",
    "\n",
    "# We don't actually use these functionalities of CATHODE, so generate a trivial number\n",
    "n_val = 1\n",
    "cathode_SR_data_train = cathode_SR_data\n",
    "dummy_data = cathode_SR_data[-n_val:]\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 7, figsize = (4*6, 3))\n",
    "\n",
    "w = 3\n",
    "for i in range(7):\n",
    "    ax[i].hist(cathode_SB_data_train[:,i], bins = 40, density = True, label = \"Train\", histtype = \"step\", color = \"red\", linewidth = w)\n",
    "    ax[i].hist(cathode_SB_data_val[:,i], bins = 40, density = True, label = \"Val\", histtype = \"step\", color = \"blue\", linewidth = w)\n",
    "    ax[i].hist(cathode_SR_data_train[:,i], bins = 40, density = True, label = \"Test\", histtype = \"step\", color = \"pink\", linewidth = w)\n",
    "        \n",
    "    ax[i].set_yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# save with labels for CATHODE\n",
    "np.save(os.path.join(data_dir, \"outerdata_train.npy\"), cathode_SB_data_train)\n",
    "np.save(os.path.join(data_dir, \"outerdata_test.npy\"), cathode_SB_data_val)\n",
    "\n",
    "np.save(os.path.join(data_dir, \"innerdata_train.npy\"), cathode_SR_data)\n",
    "np.save(os.path.join(data_dir, \"innerdata_val.npy\"), dummy_data)\n",
    "np.save(os.path.join(data_dir, \"innerdata_test.npy\"), dummy_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f654e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0cddb-6900-47d2-98ca-f636d7e60d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753812b7-b270-4126-9ee9-3072f1f2bd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277037e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae8ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f257abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec0b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa12433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72807cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0777452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd04207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa934c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
